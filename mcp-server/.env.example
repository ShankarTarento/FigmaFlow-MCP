# FigmaFlow MCP Server Configuration
# Copy this file to .env and fill in your credentials

# Figma API Token
# Get from: https://www.figma.com/settings
FIGMA_ACCESS_TOKEN=your_figma_token_here

# ============================================
# AI Configuration
# ============================================
# The platform is LLM-agnostic. Choose any option below:

# --- Option 1: LiteLLM Proxy (Recommended) ---
# Support for 100+ models via single endpoint
AI_BASE_URL=https://litellm.tarento.dev
AI_API_KEY=your_litellm_api_key
AI_MODEL=gemini-pro  # Change to: gpt-5, claude-3-5-sonnet, etc.

# --- Option 2: Direct OpenAI ---
# Uncomment and remove AI_BASE_URL above
# OPENAI_API_KEY=sk-your_openai_key
# AI_MODEL=gpt-5

# --- Option 3: Direct Anthropic (via LiteLLM) ---
# AI_BASE_URL=https://litellm.tarento.dev
# AI_API_KEY=your_litellm_key
# AI_MODEL=claude-3-5-sonnet

# --- Option 4: Local Model (Ollama) ---
# AI_BASE_URL=http://localhost:11434/v1
# AI_API_KEY=ollama
# AI_MODEL=llama3

# --- Option 5: Azure OpenAI ---
# AI_BASE_URL=https://your-resource.openai.azure.com
# AI_API_KEY=your_azure_key
# AI_MODEL=gpt-4

# ============================================
# AI Model Parameters (Optional)
# ============================================
AI_TEMPERATURE=0.3       # Creativity (0.0-1.0)
AI_MAX_TOKENS=2000       # Max response length

# ============================================
# Server Configuration
# ============================================
MCP_SERVER_PORT=3000
LOG_LEVEL=INFO

# ============================================
# Popular Model Examples:
# ============================================
# OpenAI:     gpt-5, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Google:     gemini-pro, gemini-1.5-pro, gemini-1.5-flash
# Anthropic:  claude-3-5-sonnet, claude-3-opus, claude-3-haiku
# Meta:       llama-3-70b, llama-3-8b
# Mistral:    mistral-large, mistral-medium
# Others:     command-r-plus, mixtral-8x7b
